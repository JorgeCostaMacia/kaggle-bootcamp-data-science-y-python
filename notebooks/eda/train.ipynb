{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Carga librerías <====================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Transformación de datos\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Seleccion de variables y tuning de hiperparámetros\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Métricas para evaluar un modelo de clasificación\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc, roc_curve, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# Librerías para visualización de resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz, export_text\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix, auc, plot_roc_curve, roc_curve, classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, RocCurveDisplay , roc_curve, classification_report\n",
    "\n",
    "# Para que no se corten el listado de filas y columnas al ejecutar instrucciones\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Carga Datos <========================================================\n",
    "\n",
    "datos = pd.read_csv('../../data/raw/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Definir variables <==================================================\n",
    "\n",
    "IDENTIFIER = \"MachineIdentifier\"\n",
    "LABEL = \"HasDetections\"\n",
    "\n",
    "cat_cols = []\n",
    "num_cols = []\n",
    "\n",
    "datos[IDENTIFIER] = datos[IDENTIFIER].astype(\"category\")\n",
    "datos[LABEL] = datos[LABEL].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Eliminar valores nulos <=============================================\n",
    "\n",
    "drop_cols_min_nulls = 0.7\n",
    "drop_cols_nulls = []\n",
    "\n",
    "for col in datos.columns:\n",
    "    if col != IDENTIFIER and col != LABEL and datos[col].isna().sum() / len(datos) >= drop_cols_min_nulls:\n",
    "        drop_cols_nulls.append(col)\n",
    "\n",
    "datos.drop(columns=drop_cols_nulls, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Eliminar valores mal balanceados <===================================\n",
    "\n",
    "drop_cols_min_big_cat = 70\n",
    "drop_cols_big_cat = []\n",
    "\n",
    "for col in datos.columns:\n",
    "    if col != IDENTIFIER and col != LABEL and datos[col].value_counts(normalize=True, dropna=False).values[0] * 100 >= drop_cols_min_big_cat:\n",
    "        drop_cols_big_cat.append(col)\n",
    "\n",
    "datos.drop(columns=drop_cols_big_cat, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Separar datos por tipos categoricas <================================\n",
    "\n",
    "cat_cols = datos.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "cat_cols.remove(IDENTIFIER)\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Separar datos por tipos numericas <==================================\n",
    "\n",
    "num_cols = datos.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.to_list()\n",
    "num_cols.remove(LABEL)\n",
    "\n",
    "datos[num_cols] = datos[num_cols].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Separar datos cat a numericas  <======================================\n",
    "\n",
    "cat_cols_num = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if pd.to_numeric(datos[col], errors='coerce').notnull().all():\n",
    "        cat_cols_num.append(col)\n",
    "\n",
    "for col in cat_cols_num:\n",
    "    num_cols.append(col)\n",
    "    cat_cols.remove(col)\n",
    "\n",
    "datos[cat_cols_num] = datos[cat_cols_num].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Separar datos numericas a categoricas <==============================\n",
    "\n",
    "num_cols_cat_max = 1\n",
    "num_cols_cat = []\n",
    "\n",
    "for col in num_cols:\n",
    "    if (datos[col].nunique() / datos[col].count()) * 100 <= num_cols_cat_max:\n",
    "        num_cols_cat.append(col) \n",
    "\n",
    "for col in num_cols_cat:\n",
    "    cat_cols.append(col)\n",
    "    num_cols.remove(col)\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas categoricas <=====================================\n",
    "\n",
    "pickle.dump(cat_cols, open(\"../../columns/train/cat.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas numericas <=======================================\n",
    "\n",
    "pickle.dump(num_cols, open(\"../../columns/train/num.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Imputar nulos para tipos categoricas <===============================\n",
    "\n",
    "cat_simple_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "cat_simple_imputer = cat_simple_imputer.fit(datos[cat_cols])\n",
    "datos[cat_cols] = cat_simple_imputer.transform(datos[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos SimpleImputer para tipos categoricas <=====================\n",
    "\n",
    "pickle.dump(cat_simple_imputer, open(\"../../imputers/train/cat_simple.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 3 partes <=============================\n",
    "\n",
    "cat_cols_mask_3 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 2).all():\n",
    "        cat_cols_mask_3.append(col)\n",
    "\n",
    "for col in cat_cols_mask_3:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in cat_cols_mask_3:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "\n",
    "datos.drop(columns=cat_cols_mask_3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas mascaras y versiones 3 partes <===================\n",
    "\n",
    "pickle.dump(cat_cols_mask_3, open(\"../../columns/train/cat_mask_3.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 4 partes <=============================\n",
    "\n",
    "cat_cols_mask_4 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 3).all():\n",
    "        cat_cols_mask_4.append(col)\n",
    "\n",
    "for col in cat_cols_mask_4:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\", col + \"_4\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in cat_cols_mask_4:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "    cat_cols.append(col + \"_4\")\n",
    "\n",
    "datos.drop(columns=cat_cols_mask_4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas mascaras y versiones 4 partes <===================\n",
    "\n",
    "pickle.dump(cat_cols_mask_4, open(\"../../columns/train/cat_mask_4.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 5 partes <=============================\n",
    "\n",
    "cat_cols_mask_5 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 4).all():\n",
    "        cat_cols_mask_5.append(col)\n",
    "\n",
    "for col in cat_cols_mask_5:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\", col + \"_4\", col + \"_5\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in cat_cols_mask_5:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "    cat_cols.append(col + \"_4\")\n",
    "    cat_cols.append(col + \"_5\")\n",
    "\n",
    "datos.drop(columns=cat_cols_mask_5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas mascaras y versiones 5 partes <===================\n",
    "\n",
    "pickle.dump(cat_cols_mask_5, open(\"../../columns/train/cat_mask_5.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 6 partes <=============================\n",
    "\n",
    "cat_cols_mask_6 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 5).all():\n",
    "        cat_cols_mask_6.append(col)\n",
    "\n",
    "for col in cat_cols_mask_6:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\", col + \"_4\", col + \"_5\", col + \"_6\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in cat_cols_mask_6:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "    cat_cols.append(col + \"_4\")\n",
    "    cat_cols.append(col + \"_5\")\n",
    "    cat_cols.append(col + \"_6\")\n",
    "\n",
    "datos.drop(columns=cat_cols_mask_6, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas mascaras y versiones 6 partes <===================\n",
    "\n",
    "pickle.dump(cat_cols_mask_6, open(\"../../columns/train/cat_mask_6.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar target encoder <============================================\n",
    "\n",
    "cat_cols_target_encoder_min = 5\n",
    "cat_cols_target_encoder = []\n",
    "num_cols_target_encoder = []\n",
    "\n",
    "target_encoder = ce.TargetEncoder(handle_unknown='ignore')\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].nunique() > cat_cols_target_encoder_min:\n",
    "        cat_cols_target_encoder.append(col)\n",
    "\n",
    "target_encoder = target_encoder.fit(datos[cat_cols_target_encoder], datos[LABEL])\n",
    "\n",
    "datos[cat_cols_target_encoder] = target_encoder.transform(datos[cat_cols_target_encoder])\n",
    "\n",
    "for col in cat_cols_target_encoder:\n",
    "    cat_cols.remove(col)\n",
    "    num_cols.append(col)\n",
    "    num_cols_target_encoder.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos target encoder <===========================================\n",
    "\n",
    "pickle.dump(target_encoder, open(\"../../encoders/train/target.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas target encoder <==================================\n",
    "\n",
    "pickle.dump(cat_cols_target_encoder, open(\"../../columns/train/cat_target_encoder.pkl\", 'wb'))\n",
    "pickle.dump(num_cols_target_encoder, open(\"../../columns/train/num_target_encoder.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar onehot encoder <============================================\n",
    "\n",
    "cat_cols_onehot_encoder_max = 5\n",
    "cat_cols_onehot_encoder = []\n",
    "num_cols_onehot_encoder = []\n",
    "\n",
    "# infrequent_if_exist\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].nunique() <= cat_cols_onehot_encoder_max:\n",
    "        cat_cols_onehot_encoder.append(col)\n",
    "\n",
    "onehot_encoder = onehot_encoder.fit(datos[cat_cols_onehot_encoder])\n",
    "\n",
    "onehot_datos = onehot_encoder.transform(datos[cat_cols_onehot_encoder]).toarray()\n",
    "num_cols_onehot_encoder = onehot_encoder.get_feature_names_out(cat_cols_onehot_encoder)\n",
    "\n",
    "datos[num_cols_onehot_encoder] = pd.DataFrame(onehot_datos, columns=num_cols_onehot_encoder)[num_cols_onehot_encoder]\n",
    "\n",
    "datos.drop(columns=cat_cols_onehot_encoder, inplace=True)\n",
    "\n",
    "for col in cat_cols_onehot_encoder:\n",
    "    cat_cols.remove(col)\n",
    "\n",
    "for col in num_cols_onehot_encoder:\n",
    "    num_cols.append(col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos onehot encoder <===========================================\n",
    "\n",
    "pickle.dump(onehot_encoder, open(\"../../encoders/train/onehot.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas onehot encoder <==================================\n",
    "\n",
    "pickle.dump(cat_cols_onehot_encoder, open(\"../../columns/train/cat_onehot_encoder.pkl\", 'wb'))\n",
    "pickle.dump(num_cols_onehot_encoder, open(\"../../columns/train/num_onehot_encoder.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Imputar nulos para tipos numericas <=================================\n",
    "\n",
    "num_simple_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "num_simple_imputer = num_simple_imputer.fit(datos[num_cols])\n",
    "datos[num_cols] = num_simple_imputer.transform(datos[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos SimpleImputer para tipos numericos <=======================\n",
    "\n",
    "pickle.dump(num_simple_imputer, open(\"../../imputers/train/num_simple.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Calculamos el rango intercuartílico <================================\n",
    "\n",
    "intercuartilico = {}\n",
    "\n",
    "intercuartilico[\"Q1\"] = datos[num_cols].quantile(0.25)\n",
    "intercuartilico[\"Q3\"] = datos[num_cols].quantile(0.75)\n",
    "intercuartilico[\"IQR\"] = intercuartilico[\"Q3\"] - intercuartilico[\"Q1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos Intercuartilico <==========================================\n",
    "\n",
    "pickle.dump(intercuartilico, open(\"../../interquartiles/train/intercuartilico.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Tratamiento de valores atípicos <====================================\n",
    "\n",
    "#datos[num_cols] = datos[num_cols][~((datos[num_cols] < (intercuartilico[\"Q1\"] - 1.5 * intercuartilico[\"IQR\"])) |(datos[num_cols] > (intercuartilico[\"Q3\"] + 1.5 * intercuartilico[\"IQR\"]))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Eliminar por Matriz de correlación <=================================\n",
    "\n",
    "drop_cols_corr = []\n",
    "\n",
    "corr_matrix = datos[num_cols].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "\n",
    "drop_cols_corr = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "datos.drop(columns=drop_cols_corr, inplace=True)\n",
    "\n",
    "for col in drop_cols_corr:\n",
    "    num_cols.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas Matriz correlación <==============================\n",
    "\n",
    "pickle.dump(drop_cols_corr, open(\"../../columns/train/num_correlacion.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas categoricas procesadas <==========================\n",
    "\n",
    "pickle.dump(cat_cols, open(\"../../columns/train/cat_pro.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas numericas procesadas <============================\n",
    "\n",
    "pickle.dump(num_cols, open(\"../../columns/train/num_pro.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Ordenar Datos <======================================================\n",
    "\n",
    "datos = datos[[IDENTIFIER]+cat_cols+num_cols+[LABEL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos los datos preprocesados <==================================\n",
    "\n",
    "datos.to_csv('../../data/processed/train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
