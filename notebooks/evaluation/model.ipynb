{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Carga librerías <====================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Transformación de datos\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Seleccion de variables y tuning de hiperparámetros\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Métricas para evaluar un modelo de clasificación\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc, roc_curve, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# Librerías para visualización de resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz, export_text\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix, auc, plot_roc_curve, roc_curve, classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, RocCurveDisplay , roc_curve, classification_report\n",
    "\n",
    "# Para que no se corten el listado de filas y columnas al ejecutar instrucciones\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Carga Datos <========================================================\n",
    "\n",
    "datos = pd.read_csv('../../data/processed/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Carga Procesados Train <=============================================\n",
    "\n",
    "cat_cols = pickle.load(open(\"../../columns/cat_pro.pkl\", 'rb'))\n",
    "num_cols = pickle.load(open(\"../../columns/num_pro.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Definir variables <==================================================\n",
    "\n",
    "IDENTIFIER = \"MachineIdentifier\"\n",
    "LABEL = \"HasDetections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Cambiamos tipos <====================================================\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")\n",
    "datos[num_cols] = datos[num_cols].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Datos <==============================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        datos.drop(columns = LABEL)[cat_cols+num_cols],\n",
    "                                        datos[LABEL],\n",
    "                                        random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.691     0.443     0.540    111718\n",
      "         1.0      0.589     0.801     0.679    111319\n",
      "\n",
      "    accuracy                          0.622    223037\n",
      "   macro avg      0.640     0.622     0.609    223037\n",
      "weighted avg      0.640     0.622     0.609    223037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================> DecisionTreeClassifier <=============================================\n",
    "\n",
    "modelo_DecisionTreeClassifier = DecisionTreeClassifier(criterion= \"entropy\", max_depth=5, min_samples_leaf=3, random_state = 123)\n",
    "\n",
    "modelo_DecisionTreeClassifier = modelo_DecisionTreeClassifier.fit(X_train, y_train)\n",
    "\n",
    "predicciones_DecisionTreeClassifier = modelo_DecisionTreeClassifier.predict(X = X_test)\n",
    "pred_proba_DecisionTreeClassifier = modelo_DecisionTreeClassifier.predict_proba(X = X_test)\n",
    "\n",
    "print(classification_report(y_test, predicciones_DecisionTreeClassifier, digits=3, zero_division=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.660     0.608     0.633    111718\n",
      "         1.0      0.636     0.686     0.660    111319\n",
      "\n",
      "    accuracy                          0.647    223037\n",
      "   macro avg      0.648     0.647     0.647    223037\n",
      "weighted avg      0.648     0.647     0.646    223037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================> LGBMClassifier <=====================================================\n",
    "\n",
    "modelo_LGBMClassifier = lgb.LGBMClassifier(learning_rate = 0.2, max_depth=5, n_estimators= 25, num_leaves=50, random_state=123)\n",
    "\n",
    "modelo_LGBMClassifier = modelo_LGBMClassifier.fit(X_train, y_train)\n",
    "\n",
    "predicciones_LGBMClassifier = modelo_LGBMClassifier.predict(X = X_test)\n",
    "pred_proba_LGBMClassifier = modelo_LGBMClassifier.predict_proba(X = X_test)\n",
    "\n",
    "print(classification_report(y_test, predicciones_LGBMClassifier, digits=3, zero_division=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.502     0.583     0.539    111718\n",
      "         1.0      0.501     0.420     0.457    111319\n",
      "\n",
      "    accuracy                          0.501    223037\n",
      "   macro avg      0.501     0.501     0.498    223037\n",
      "weighted avg      0.501     0.501     0.498    223037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================> LogisticRegression <=================================================\n",
    "\n",
    "modelo_LogisticRegression = LogisticRegression(random_state = 123)\n",
    "\n",
    "modelo_LogisticRegression = modelo_LogisticRegression.fit(X_train, y_train)\n",
    "\n",
    "predicciones_LogisticRegression = modelo_LogisticRegression.predict(X = X_test)\n",
    "pred_proba_LogisticRegression = modelo_LogisticRegression.predict_proba(X = X_test)\n",
    "\n",
    "print(classification_report(y_test, predicciones_LogisticRegression, digits=3, zero_division=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.659     0.562     0.607    111718\n",
      "         1.0      0.617     0.708     0.659    111319\n",
      "\n",
      "    accuracy                          0.635    223037\n",
      "   macro avg      0.638     0.635     0.633    223037\n",
      "weighted avg      0.638     0.635     0.633    223037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================> RandomForestClassifier <=============================================\n",
    "\n",
    "modelo_RandomForestClassifier = RandomForestClassifier(criterion= \"entropy\", max_depth=5, min_samples_leaf=3, random_state = 123)\n",
    "\n",
    "modelo_RandomForestClassifier = modelo_RandomForestClassifier.fit(X_train, y_train)\n",
    "\n",
    "predicciones_RandomForestClassifier = modelo_RandomForestClassifier.predict(X = X_test)\n",
    "pred_proba_RandomForestClassifier = modelo_RandomForestClassifier.predict_proba(X = X_test)\n",
    "\n",
    "print(classification_report(y_test, predicciones_RandomForestClassifier, digits=3, zero_division=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.663     0.650     0.656    111718\n",
      "         1.0      0.655     0.668     0.662    111319\n",
      "\n",
      "    accuracy                          0.659    223037\n",
      "   macro avg      0.659     0.659     0.659    223037\n",
      "weighted avg      0.659     0.659     0.659    223037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================================> XGBClassifier <======================================================\n",
    "\n",
    "modelo_XGBClassifier = xgb.XGBClassifier(booster=\"gbtree\", max_depth=5, objective=\"binary:logistic\", random_state=123)\n",
    "\n",
    "modelo_XGBClassifier = modelo_XGBClassifier.fit(X_train, y_train)\n",
    "\n",
    "predicciones_XGBClassifier = modelo_XGBClassifier.predict(X = X_test)\n",
    "pred_proba_XGBClassifier = modelo_XGBClassifier.predict_proba(X = X_test)\n",
    "\n",
    "print(classification_report(y_test, predicciones_XGBClassifier, digits=3, zero_division=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
