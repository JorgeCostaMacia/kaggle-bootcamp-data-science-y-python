{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Carga librerías <====================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Transformación de datos\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Seleccion de variables y tuning de hiperparámetros\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Métricas para evaluar un modelo de clasificación\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc, roc_curve, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# Librerías para visualización de resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tratamiento de datos\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Gráficos\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz, export_text\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix, auc, plot_roc_curve, roc_curve, classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, RocCurveDisplay , roc_curve, classification_report\n",
    "\n",
    "# Para que no se corten el listado de filas y columnas al ejecutar instrucciones\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Carga Datos <========================================================\n",
    "\n",
    "datos = pd.read_csv('../data/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Eliminar valores nulos <=============================================\n",
    "\n",
    "drop_cols_min_nulls = 0.7\n",
    "drop_cols_nulls = []\n",
    "\n",
    "for col in datos.columns:\n",
    "    if datos[col].isna().sum() / len(datos) >= drop_cols_min_nulls:\n",
    "        drop_cols_nulls.append(col)\n",
    "\n",
    "datos.drop(columns=drop_cols_nulls, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Separar datos por tipos categoricas <================================\n",
    "\n",
    "cat_cols = datos.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "cat_cols.remove('MachineIdentifier')\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Separar datos por tipos numericas <==================================\n",
    "\n",
    "numeric_cols = datos.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.to_list()\n",
    "numeric_cols.remove('HasDetections')\n",
    "\n",
    "datos[numeric_cols] = datos[numeric_cols].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Separar datos numericas a categoricas <==============================\n",
    "\n",
    "numeric_cols_cat_max = 1\n",
    "numeric_cols_cat = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if (datos[col].nunique() / datos[col].count()) * 100 <= numeric_cols_cat_max:\n",
    "        numeric_cols_cat.append(col) \n",
    "\n",
    "for col in numeric_cols_cat:\n",
    "    cat_cols.append(col)\n",
    "    numeric_cols.remove(col)\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas categoricas <=====================================\n",
    "\n",
    "pickle.dump(cat_cols, open(\"../eda/cat_cols_raw.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas numericas <=======================================\n",
    "\n",
    "pickle.dump(numeric_cols, open(\"../eda/numeric_cols_raw.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Imputar nulos para tipos categoricas <===============================\n",
    "\n",
    "imp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "imp_cat = imp_cat.fit(datos[cat_cols])\n",
    "datos[cat_cols] = imp_cat.transform(datos[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos SimpleImputer para tipos categoricas <=====================\n",
    "\n",
    "pickle.dump(imp_cat, open(\"../eda/symple_imputer_cat.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 3 partes <=============================\n",
    "\n",
    "mask_cols_3 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 2).all():\n",
    "        mask_cols_3.append(col)\n",
    "\n",
    "for col in mask_cols_3:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in mask_cols_3:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "\n",
    "datos.drop(columns=mask_cols_3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 4 partes <=============================\n",
    "\n",
    "mask_cols_4 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 3).all():\n",
    "        mask_cols_4.append(col)\n",
    "\n",
    "for col in mask_cols_4:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\", col + \"_4\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in mask_cols_4:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "    cat_cols.append(col + \"_4\")\n",
    "\n",
    "datos.drop(columns=mask_cols_4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 5 partes <=============================\n",
    "\n",
    "mask_cols_5 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 4).all():\n",
    "        mask_cols_5.append(col)\n",
    "\n",
    "for col in mask_cols_5:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\", col + \"_4\", col + \"_5\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in mask_cols_5:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "    cat_cols.append(col + \"_4\")\n",
    "    cat_cols.append(col + \"_5\")\n",
    "\n",
    "datos.drop(columns=mask_cols_5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar mascaras y versiones 6 partes <=============================\n",
    "\n",
    "mask_cols_6 = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].notnull().all() and datos[col].astype(str).apply(lambda x: x.count('.') == 5).all():\n",
    "        mask_cols_6.append(col)\n",
    "\n",
    "for c in mask_cols_6:\n",
    "    datos[[col + \"_1\", col + \"_2\", col + \"_3\", col + \"_4\", col + \"_5\", col + \"_6\"]] = datos[col].str.split(\".\", expand=True)\n",
    "\n",
    "for col in mask_cols_6:\n",
    "    cat_cols.remove(col)\n",
    "    cat_cols.append(col + \"_1\")\n",
    "    cat_cols.append(col + \"_2\")\n",
    "    cat_cols.append(col + \"_3\")\n",
    "    cat_cols.append(col + \"_4\")\n",
    "    cat_cols.append(col + \"_5\")\n",
    "    cat_cols.append(col + \"_6\")\n",
    "\n",
    "datos.drop(columns=mask_cols_6, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar target encoder <============================================\n",
    "\n",
    "cat_cols_target_encoder_min = 5\n",
    "cat_cols_target_encoder = []\n",
    "\n",
    "target_encoder = ce.TargetEncoder(handle_unknown='ignore')\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].nunique() > cat_cols_target_encoder_min:\n",
    "        cat_cols_target_encoder.append(col)\n",
    "\n",
    "for col in cat_cols_target_encoder:\n",
    "    cat_cols.remove(col)\n",
    "\n",
    "target_encoder = target_encoder.fit(datos[cat_cols_target_encoder], datos['HasDetections'])\n",
    "encoded_data_cat_target_encoder = target_encoder.transform(datos[cat_cols_target_encoder])\n",
    "\n",
    "datos = pd.concat([datos.drop(columns=cat_cols_target_encoder), encoded_data_cat_target_encoder], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos target encoder <===========================================\n",
    "\n",
    "pickle.dump(imp_cat, open(\"../eda/target_encoder_cat.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Procesar onehot encoder <============================================\n",
    "\n",
    "cat_cols_onehot_encoder_max = 5\n",
    "cat_cols_onehot_encoder = []\n",
    "\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "for col in cat_cols:\n",
    "    if datos[col].nunique() <= cat_cols_onehot_encoder_max:\n",
    "        cat_cols_onehot_encoder.append(col)\n",
    "\n",
    "for col in cat_cols_onehot_encoder:\n",
    "    cat_cols.remove(col)\n",
    "\n",
    "onehot_encoder = onehot_encoder.fit(datos[cat_cols_onehot_encoder])\n",
    "encoded_cols_onehot_encoder = onehot_encoder.transform(datos[cat_cols_onehot_encoder]).toarray()\n",
    "encoded_data_cat_cols_onehot_encoder = pd.DataFrame(encoded_cols_onehot_encoder, columns=onehot_encoder.get_feature_names_out(cat_cols_onehot_encoder))\n",
    "\n",
    "datos = pd.concat([datos.drop(columns=cat_cols_onehot_encoder), encoded_data_cat_cols_onehot_encoder], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Reiniciar Separar datos por tipos categoricas <======================\n",
    "\n",
    "cat_cols = datos.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "cat_cols.remove('MachineIdentifier')\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Reiniciar Separar datos por tipos numericas <========================\n",
    "\n",
    "numeric_cols = datos.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.to_list()\n",
    "numeric_cols.remove('HasDetections')\n",
    "\n",
    "datos[numeric_cols] = datos[numeric_cols].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Reiniciar datos numericas a categoricas <============================\n",
    "\n",
    "numeric_cols_cat_max = 1\n",
    "numeric_cols_cat = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if (datos[col].nunique() / datos[col].count()) * 100 <= numeric_cols_cat_max:\n",
    "        numeric_cols_cat.append(col) \n",
    "\n",
    "for col in numeric_cols_cat:\n",
    "    cat_cols.append(col)\n",
    "    numeric_cols.remove(col)\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Calculamos el rango intercuartílico <================================\n",
    "\n",
    "intercuartilico = {}\n",
    "\n",
    "intercuartilico[\"Q1\"] = datos[numeric_cols].quantile(0.25)\n",
    "intercuartilico[\"Q3\"] = datos[numeric_cols].quantile(0.75)\n",
    "intercuartilico[\"IQR\"] = intercuartilico[\"Q3\"] - intercuartilico[\"Q1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos Intercuartilico <==========================================\n",
    "\n",
    "pickle.dump(intercuartilico, open(\"../eda/intercuartilico.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Tratamiento de valores atípicos <====================================\n",
    "\n",
    "datos[numeric_cols] = datos[numeric_cols][~((datos[numeric_cols] < (intercuartilico[\"Q1\"] - 1.5 * intercuartilico[\"IQR\"])) |(datos[numeric_cols] > (intercuartilico[\"Q3\"] + 1.5 * intercuartilico[\"IQR\"]))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Eliminar por Matriz de correlación <=================================\n",
    "\n",
    "drop_cols_corr = []\n",
    "\n",
    "corr_matrix = datos[numeric_cols].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "\n",
    "drop_cols_corr = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "datos.drop(columns=drop_cols_corr, inplace=True)\n",
    "\n",
    "for col in drop_cols_corr:\n",
    "    numeric_cols.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Imputar nulos para tipos numericas <=================================\n",
    "\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "imp_num = imp_num.fit(datos[numeric_cols])\n",
    "datos[numeric_cols] = imp_num.transform(datos[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos SimpleImputer para tipos numericos <=======================\n",
    "\n",
    "pickle.dump(imp_num, open(\"../eda/symple_imputer_num.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Reiniciar Separar datos por tipos categoricas <======================\n",
    "\n",
    "cat_cols = datos.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "cat_cols.remove('MachineIdentifier')\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Reiniciar Separar datos por tipos numericas <========================\n",
    "\n",
    "numeric_cols = datos.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.to_list()\n",
    "numeric_cols.remove('HasDetections')\n",
    "\n",
    "datos[numeric_cols] = datos[numeric_cols].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Reiniciar datos numericas a categoricas <============================\n",
    "\n",
    "numeric_cols_cat_max = 1\n",
    "numeric_cols_cat = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if (datos[col].nunique() / datos[col].count()) * 100 <= numeric_cols_cat_max:\n",
    "        numeric_cols_cat.append(col) \n",
    "\n",
    "for col in numeric_cols_cat:\n",
    "    cat_cols.append(col)\n",
    "    numeric_cols.remove(col)\n",
    "\n",
    "datos[cat_cols] = datos[cat_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas categoricas <=====================================\n",
    "\n",
    "pickle.dump(cat_cols, open(\"../eda/cat_cols_pre.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos columnas numericas <=======================================\n",
    "\n",
    "pickle.dump(numeric_cols, open(\"../eda/numeric_cols_pre.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Ordenar variables <==================================================\n",
    "\n",
    "ordered_columns = cat_cols+numeric_cols\n",
    "datos = datos[[\"MachineIdentifier\"]+ordered_columns+['HasDetections']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================> Guardamos los datos preprocesados <==================================\n",
    "\n",
    "datos.to_csv('../data/train_pre.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
