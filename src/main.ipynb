{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Instalación librerías <==============================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "#%pip install pandas    # NO HACE FALTA INSTALAR\n",
    "#%pip install numpy     # NO HACE FALTA INSTALAR\n",
    "#%pip install pickle    # NO HACE FALTA INSTALAR\n",
    "#%pip install sklearn   # NO HACE FALTA INSTALAR\n",
    "\n",
    "#%pip install scikit-learn          # DESCOMENTAR LA PRIMERA VEZ\n",
    "#%pip install category_encoders     # DESCOMENTAR LA PRIMERA VEZ\n",
    "#%pip install lightgbm              # DESCOMENTAR LA PRIMERA VEZ\n",
    "#%pip install matplotlib            # DESCOMENTAR LA PRIMERA VEZ\n",
    "#%pip install seaborn               # DESCOMENTAR LA PRIMERA VEZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Carga librerías <====================================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Transformación de datos\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "# Modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Seleccion de variables y tuning de hiperparámetros\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# Métricas para evaluar un modelo de clasificación\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc, roc_curve, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "# Librerías para visualización de resultados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para que no se corten el listado de filas y columnas al ejecutar instrucciones\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Carga Datos <========================================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "df = pd.read_csv('../data/train.csv', low_memory=False)\n",
    "df = df.sample(10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =====================> EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Exploración número de columnas <=====================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Exploración estadisticas basicas col numericas <=====================\n",
    "# ==================================================================================================================\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Exploración estadisticas basicas col objectos <=====================\n",
    "# ==================================================================================================================\n",
    "\n",
    "df.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Exploración 20 primeras filas <======================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Exploración tipos <==================================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Exploración nulos <==================================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Exploración valores y estadísticas <=================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "stats = []\n",
    "# Unique Values         col \n",
    "# Unique Values         df[col].nunique() \n",
    "# Unique Values %       (df[col].nunique() / df[col].count()) * 100\n",
    "# Missing Values %      df[col].isnull().sum() * 100 / df.shape[0]\n",
    "# Biggest Category %    df[col].value_counts(normalize=True, dropna=False).values[0] * 100\n",
    "# Type                  df[col].dtype\n",
    "\n",
    "for col in df.columns:\n",
    "    stats.append((col, df[col].nunique(), (df[col].nunique() / df[col].count()) * 100, df[col].isnull().sum() * 100 / df.shape[0], df[col].value_counts(normalize=True, dropna=False).values[0] * 100, df[col].dtype))\n",
    "    \n",
    "stats_df = pd.DataFrame(stats, columns=['Feature', 'Unique Values', 'Unique Values %', 'Missing Values %', 'Biggest Category %', 'Type'])\n",
    "stats_df.sort_values('Missing Values %', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar valores nulos <=============================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "drop_cols_min = 0.6\n",
    "drop_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].isna().sum() / len(df) > drop_cols_min:\n",
    "        drop_cols.append(c)\n",
    "        \n",
    "for c in drop_cols:\n",
    "    df = df.drop(c, axis=1)\n",
    "\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar valores muy balanceados <===================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "drop_cols_min_big_cat = 70\n",
    "drop_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].value_counts(normalize=True, dropna=False).values[0] * 100 >= drop_cols_min_big_cat:\n",
    "        drop_cols.append(c)\n",
    "        \n",
    "for c in drop_cols:\n",
    "    df = df.drop(c, axis=1)\n",
    "\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar valores muy balanceados <===================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "drop_cols_min_unique = 2\n",
    "drop_cols_min_big_cat = 60\n",
    "drop_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].nunique() <= drop_cols_min_unique and df[c].value_counts(normalize=True, dropna=False).values[0] * 100 >= drop_cols_min_big_cat:\n",
    "        drop_cols.append(c)\n",
    "        \n",
    "for c in drop_cols:\n",
    "    df = df.drop(c, axis=1)\n",
    "\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar imputar nulos <=============================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "# Se imputa todos los valores nulos como la moda, ya que en su mayoria son categoricos o identificadores\n",
    "\n",
    "imputed_min_unique = 100\n",
    "imputed_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].isnull().any() and ((df[c].nunique() / df[c].count()) * 100) <= imputed_min_unique:\n",
    "        imputed_cols.append(c)\n",
    "        \n",
    "for c in imputed_cols:\n",
    "    df[c] = df[c].fillna(df[c].mode()[0])\n",
    "\n",
    "print(imputed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar mascaras y versiones 3 partes <=============================\n",
    "# ==================================================================================================================\n",
    "\n",
    "mask_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].notnull().all() and df[c].astype(str).apply(lambda x: x.count('.') == 2).all():\n",
    "        mask_cols.append(c)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df[[c + \"_1\", c + \"_2\", c + \"_3\"]] = df[c].str.split(\".\", expand=True)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df = df.drop(c, axis=1)\n",
    "\n",
    "print(mask_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar mascaras y versiones 4 partes <=============================\n",
    "# ==================================================================================================================\n",
    "\n",
    "mask_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].notnull().all() and df[c].astype(str).apply(lambda x: x.count('.') == 3).all():\n",
    "        mask_cols.append(c)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df[[c + \"_1\", c + \"_2\", c + \"_3\", c + \"_4\"]] = df[c].str.split(\".\", expand=True)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df = df.drop(c, axis=1)\n",
    "\n",
    "print(mask_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar mascaras y versiones 5 partes <=============================\n",
    "# ==================================================================================================================\n",
    "\n",
    "mask_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].notnull().all() and df[c].astype(str).apply(lambda x: x.count('.') == 4).all():\n",
    "        mask_cols.append(c)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df[[c + \"_1\", c + \"_2\", c + \"_3\", c + \"_4\", c + \"_5\"]] = df[c].str.split(\".\", expand=True)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df = df.drop(c, axis=1)\n",
    "\n",
    "print(mask_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar mascaras y versiones 6 partes <=============================\n",
    "# ==================================================================================================================\n",
    "\n",
    "mask_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].notnull().all() and df[c].astype(str).apply(lambda x: x.count('.') == 5).all():\n",
    "        mask_cols.append(c)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df[[c + \"_1\", c + \"_2\", c + \"_3\", c + \"_4\", c + \"_5\", c + \"_6\"]] = df[c].str.split(\".\", expand=True)\n",
    "\n",
    "for c in mask_cols:\n",
    "    df = df.drop(c, axis=1)\n",
    "\n",
    "print(mask_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar Unique Tipos Cat <==========================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "typed_min_unique = 10\n",
    "typed_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if ((df[c].nunique() / df[c].count()) * 100) <= typed_min_unique:\n",
    "        typed_cols.append(c)\n",
    "        \n",
    "for c in typed_cols:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "print(typed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================\n",
    "# ===========================================> Procesar Object Tipos Cat <==========================================\n",
    "# ==================================================================================================================\n",
    "\n",
    "typed_cols = []\n",
    "\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == \"object\":\n",
    "        typed_cols.append(c)\n",
    "        \n",
    "for c in typed_cols:\n",
    "   df[c] = df[c].astype(\"category\")\n",
    "\n",
    "print(typed_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
